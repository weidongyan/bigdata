    - name: unpack kafka package
      unarchive:
        src: files/apache-flume-1.7.0-bin.tar.gz
        dest: /home/{{ HadoopUser }}
        owner: "{{ HadoopUser }}"

    - name: create flume start script
      copy:
        content: |
          bin/flume-ng agent --conf conf  --conf-file conf/logagent.properties --name LogAgent -Dflume.root.logger=DEBUG,console
        dest: /home/{{ HadoopUser }}/apache-flume-1.7.0-bin/flume_LogAgent_start.sh
        mode: 0755

    - name: create flume configuration file
      copy:
        content: |
          LogAgent.sources = mysource
          LogAgent.channels = mychannel
          LogAgent.sinks = mysink
          LogAgent.sources.mysource.type = spooldir
          LogAgent.sources.mysource.channels = mychannel
          LogAgent.sources.mysource.spoolDir =/tmp/logs
          LogAgent.sinks.mysink.channel = mychannel
          LogAgent.sinks.mysink.type = hdfs
          LogAgent.sinks.mysink.hdfs.path = hdfs://{{ NameNode }}:9000/data/newlogs/%Y/%m/%d/%H/
          LogAgent.sinks.mysink.hdfs.batchSize = 1000
          LogAgent.sinks.mysink.hdfs.rollSize = 0
          LogAgent.sinks.mysink.hdfs.rollCount = 10000
          LogAgent.sinks.mysink.hdfs.useLocalTimeStamp = true
          LogAgent.channels.mychannel.type = memory
          LogAgent.channels.mychannel.capacity = 10000
          LogAgent.channels.mychannel.transactionCapacity = 100

          #!/bin/bash
          bin/kafka-server-start.sh -daemon config/server.properties
        dest: /home/{{ HadoopUser }}/apache-flume-1.7.0-bin/conf/logagent.properties
        mode: 0644
